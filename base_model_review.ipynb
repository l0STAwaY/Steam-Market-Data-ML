{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base sentiment labling -- prediciting labels with non missing/accurate data(sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 10 stored elements and shape (1, 39930)>\n",
      "  Coords\tValues\n",
      "  (0, 2552)\t0.12290841802572704\n",
      "  (0, 2011)\t0.2418367015465236\n",
      "  (0, 2277)\t0.20055034570669786\n",
      "  (0, 32473)\t0.29318684506672227\n",
      "  (0, 36400)\t0.2722228098558392\n",
      "  (0, 34662)\t0.24447618305051694\n",
      "  (0, 12694)\t0.3261212931093063\n",
      "  (0, 26528)\t0.4466744425422766\n",
      "  (0, 32415)\t0.11219304954593112\n",
      "  (0, 31503)\t0.5898264704040868\n",
      "\n",
      "Evaluation Results on Test Data:\n",
      "Accuracy:  0.8649506135887459\n",
      "Precision: 0.8581362375605909\n",
      "Recall:    0.8286273977149197\n",
      "Accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "review_data = pd.read_csv(\"/Users/apple/Documents/GitHub/Steam-Market-Data-ML/cleaned_reviews.csv\")\n",
    "\n",
    "\n",
    "print(review_data[\"review_comment\"].isna().sum())\n",
    "review_data[\"review_comment\"] = review_data[\"review_comment\"].fillna(\"\") \n",
    "review_data[\"recommend\"] = review_data[\"recommend\"].map({\"Recommended\": 1, \"Not Recommended\": 0})\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "review_vectorized = vectorizer.fit_transform(review_data[\"review_comment\"])\n",
    "review_X = vectorizer.fit_transform(review_data[\"review_comment\"])  # Convert text to TF-IDF features\n",
    "review_y = review_data[\"recommend\"]\n",
    "\n",
    "\n",
    "# print(vectorizer.get_feature_names_out())  # Shows vocabulary\n",
    "review_X_train, review_X_test, review_y_train, review_y_test = train_test_split(review_X, review_y, test_size=0.2, random_state=2025)\n",
    "logit_review_model = LogisticRegression()\n",
    "\n",
    "\n",
    "logit_review_model.fit(review_X_train, review_y_train)\n",
    "\n",
    "review_y_pred = logit_review_model.predict(review_X_test)\n",
    "\n",
    "# print(review_X_train.shape[0])\n",
    "\n",
    "accuracy = accuracy_score(review_y_test, review_y_pred )\n",
    "precision = precision_score(review_y_test, review_y_pred ,average='macro')\n",
    "recall = recall_score(review_y_test, review_y_pred ,average='macro')\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation Results on Test Data:\")\n",
    "print(f\"Accuracy:  {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(I suspect it would fail to run due to the high dimension, but I'm trying anyways )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions using PCA\n",
    "pca = PCA(n_components=10000)  # You can experiment with this number\n",
    "review_X_pca = pca.fit_transform(review_X.toarray())  # Apply PCA on the sparse matrix\n",
    "\n",
    "print(\"PCA dones\")\n",
    "# Now use SVM with reduced dimensions\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(review_X_pca, review_y_train)\n",
    "\n",
    "review_y_pred_svm = svm_model.predict(review_X_pca)\n",
    "\n",
    "accuracy_svm = accuracy_score(review_y_test, review_y_pred_svm)\n",
    "precision_svm = precision_score(review_y_test, review_y_pred_svm, average='macro')\n",
    "recall_svm = recall_score(review_y_test, review_y_pred_svm, average='macro')\n",
    "\n",
    "print(\"\\nSVM with PCA Evaluation Results:\")\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {precision_svm:.4f}\")\n",
    "print(f\"Recall: {recall_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We face memory and runtime issue despite using pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc410",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
